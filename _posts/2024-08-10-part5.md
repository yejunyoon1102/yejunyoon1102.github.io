---
layout: post
title: "데이터 분석 : Part.5 데이터 사전 처리"
date: 2024-08-10
categories: [Data Analysis, Pandas]
---
# Part5. 데이터 사전 처리

## 누락 데이터 처리

데이터프레임에는 원소 데이터 값이 종종 누락되는 경우가 있음

일반적으로 누락 데이터를 **NaN**(Not a Number)으로 표시함!

### 누락 데이터 확인

```python
# 라이브러리 불러오기
import seaborn as sns

# titanic 데이터셋 가져오기
df = sns.load_dataset('titanic')

# 데이터프레임 개요
df.info()
```

![1.png](/assets/img/posts/PANDAS/part5/1.png)

전체 데이터가 891개인데 ‘age’(177개) 와 ‘deck’ (688개)열에 결측치가 있는 모습

**`value_counts()`** 메소드를 이용하여 누락 데이터 개수 확인, 이 때 개수를 확인하려면 반드시 **`dropna=False`** 옵션을 사용해야!!!(그렇지 않으면 NaN값을 제외하고 유효한 데이터의 개수만을 구함)

```python
# deck 열의 NaN 개수 계산하기
df['deck'].value_counts(dropna=False) 
```

![2.png](/assets/img/posts/PANDAS/part5/2.png)

누락 데이터를 찾는 직접적인 방법으로,

**`isnull()`** : 누락 데이터면 True를 반환하고, 유효한 데이터가 존재하면 False를 반환

**`notnull()`** : 유효한 데이터가 존재하면 True를 반환하고, 누락 데이터면 False를 반환

```python
# isnull() 메서드로 상위 5개에서 누락 데이터 개수 구하기
df.head().isnull().sum(axis=0)
```

### 누락 데이터 제거

열을 삭제하면 분석 대상이 갖는 특성(변수)를 제거함

행을 삭제하면 분석 대상의 관측값(레코드)을 제거함

**`dropna()`** 메소드를 활용해서 제거함!!

- **`axis=0`** : 열 단위로 연산을 수행 / 행 단위로 삭제
- **`axis=1`** : 행 단위로 연산을 수행 / 열 단위로 삭제

```python
# isnull() 메서드를 합계로 집계하여 각 열의 NaN 개수 계산하기
df.isnull().sum(axis=0)
```

![3.png](/assets/img/posts/PANDAS/part5/3.png)

```python
# NaN 값이 500개 이상인 열을 모두 삭제 - deck 열(891개 중 688개의 NaN 값)
df_thresh = df.dropna(axis=1, thresh=500)  
print(df_thresh.columns)

>>>
Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',
       'embarked', 'class', 'who', 'adult_male', 'embark_town', 'alive',
       'alone'],
      dtype='object')
```

```python
# age 열에 나이 데이터가 없는 모든 행을 삭제 - age 열(891개 중 177개의 NaN 값)
df_age = df.dropna(subset=['age'], how='any', axis=0)  
print(len(df_age))

>>>

714
```

```python
# age 열, deck 열 양쪽 모두 데이터가 없는 행을 삭제 
df_age_deck = df.dropna(subset=['age', 'deck'], how='all', axis=0)  
print(len(df_age_deck))

>>>
733
```

**`how=’any’`** 옵션을 사용하면 NaN 값이 하나라도 존재하면 삭제함

**`how=’all’`** 옵션을 사용하면 모든 데이터가 NaN값일 경우에만 삭제함

### 누락 데이터 치환

무작정 삭제보다는 최대한 살려서 활용하는 게 좋음

보편적으로 평균값, 최빈값 등을 활용함

**`fillna()`** 메소드를 이용!!, 원본 객체를 변경하려면 **`inplace=True`** 옵션을 추가해야

```python
# age 열의 첫 10개 데이터 출력 (5 행에 NaN 값)
df['age'].head(10)
```

![4.png](/assets/img/posts/PANDAS/part5/4.png)

```python
# age 열의 NaN값을 다른 나이 데이터의 평균으로 변경하기
mean_age = df['age'].mean(axis=0)   # age 열의 평균 계산 (NaN 값 제외)
df['age'] = df['age'].fillna(mean_age)

# age 열의 첫 10개 데이터 출력 (5 행에 NaN 값이 평균으로 대체)
df['age'].head(10)
```

![5.png](/assets/img/posts/PANDAS/part5/5.png)

```python
# embark_town 열의 829행의 NaN 데이터 출력
df['embark_town'][825:830]
```

![6.png](/assets/img/posts/PANDAS/part5/6.png)

```python
# embark_town 열의 최빈값(승선도시 중에서 가장 많이 출현한 값) 찾기 
most_freq = df['embark_town'].mode()[0]
아니면
most_freq = df['embark_town'].value_counts(dropna=True).idxmax()

# embark_town 열의 NaN값을 최빈값으로 대체하기
df['embark_town'] = df['embark_town'].fillna(most_freq)

# embark_town 열 829행의 NaN 데이터 출력 (NaN 값이 most_freq 값으로 대체)
df['embark_town'][825:830]
```

![7.png](/assets/img/posts/PANDAS/part5/7.png)

앞이나 뒤에서 이웃하고 있는 값으로 치환하려면

**`method=’ffill’`** 옵션을 추가하면 NaN이 있는 행의 직전 행에 있는 값으로 치환

**`method=’bfill’`** 옵션을 추가하면 NaN이 있는 행의 다음 행에 있는 값으로 치환

```python
# 829행의 값이 NaN일 때

# embark_town 열의 NaN값을 바로 앞에 있는 828행의 값으로 변경하기
df['embark_town'] = df['embark_town'].ffill()

# embark_town 열의 NaN값을 바로 뒤에 있는 831행의 값으로 변경하기
df2['embark_town'] = df2['embark_town'].bfill()

```

## 중복 데이터 처리

하나의 데이터셋에서 동일한 관측값이 2개 이상 중복되는 경우 분석 결과를 왜곡할 수 있음

### 중복 데이터 확인

**`duplicated()`** 메소드 이용

전에 나온 행들과 비교하여 중복되는 행이면 True, 처음 나오는 행이면 False 반환

### 중복 데이터 제거

**`drop_duplicated()`** 메소드 이용, 원본 객체를 변경하려면 **`inplace=True`** 옵션 사용

subset 옵션에 열 이름의 리스트를 전달

## 데이터 표준화

서로 다른 단위가 섞여 있거나 같은 대상을 다른 형식으로 표현한 경우에,

데이터 포맷을 일관성 있게 표준화 하는 작업 필요!!

### 단위 환산

서로 다른 측정 단위를 사용 할 때, 같은 단위로 맞출 필요가 있음

```python
< mile/gallon 에서 km/L 로 바꾸기>

# mpg(mile per gallon)를 kpl(kilometer per liter)로 변환 (mpg_to_kpl = 0.425)
mpg_to_kpl = 1.60934 / 3.78541

# mpg 열에 0.425를 곱한 결과를 새로운 열(kpl)에 추가
df['kpl'] = df['mpg'] * mpg_to_kpl

# kpl 열을 소수점 아래 둘째 자리에서 반올림 
df['kpl'] = df['kpl'].round(2)
```

### 자료형 변환

숫자가 문자열(object)로 저장된 경우에 숫자형(int 또는 float)로 변환해야

```python
# 각 열의 자료형 확인
print(df.dtypes)

>>>
mpg             float64
cylinders         int64
displacement    float64
horsepower       object
weight          float64
acceleration    float64
model year        int64
origin            int64
name             object
dtype: object

# horsepower 열의 고유값 확인
print(df['horsepower'].unique())
```

![8.png](/assets/img/posts/PANDAS/part5/8.png)

? 값이 존재 → 이것 때문에 object로 판단했구나!

```python
# 누락 데이터('?') 삭제 
import numpy as np
df['horsepower'] = df['horsepower'].replace('?', np.nan)      # '?'을 np.nan으로 변경
df = df.dropna(subset=['horsepower'], axis=0)                 # 누락데이터 행을 삭제
df['horsepower'] = df['horsepower'].astype('float')           # 문자열을 실수형으로 변환

# horsepower 열의 자료형 확인
print(df['horsepower'].dtypes)  

>>>
float64
```

```python
# origin 열의 고유값 확인
print(df['origin'].unique())

# 정수형 데이터를 문자형 데이터로 변환 
df['origin'] = df['origin'].replace({1:'USA', 2:'EU', 3:'JAPAN'})

# origin 열의 고유값과 자료형 확인
print(df['origin'].unique())
print(df['origin'].dtypes) 

>>>
[1 3 2]
['USA' 'JAPAN' 'EU']
object
```

유한 개의 고유값이 반복적으로 나타나는 경우에는 범주형(category) 데이터로 표현하는 것이 효율적!!

**`astype(’category’)`** 메소드 사용하면 범주형 데이터로 변환

```python
# origin 열의 문자열 자료형을 범주형으로 변환
df['origin'] = df['origin'].astype('category')     
print(df['origin'].dtypes) 

# 범주형을 문자열로 다시 변환
df['origin'] = df['origin'].astype('str')     
print(df['origin'].dtypes)

>>>
category
object
```

## 범주형(카테고리) 데이터 처리

### 구간 분할

연속 데이터를 그대로 사용하기 보다는 일정한 구간(bin)으로 나눠서 분석하는 것 이 효율적

판다스 **`pd.cut()`** 함수를 이용하면 연속 데이터를 여러 구간으로 나누고 범주형 데이터로 변환

![9.png](/assets/img/posts/PANDAS/part5/9.png)

**`np.histogram()`** 함수에 나누려는 구간(bin) 개수를 **`bins`** 옵션에 입력하면 각 구간에 속하는 값의 개수(count) 와 경계값 리스트(bin_dividers)를 반환함

```python
# horsepower 열의 누락 데이터('?') 삭제하고 실수형으로 변환
df['horsepower'] = df['horsepower'].replace('?', np.nan)      # '?'을 np.nan으로 변경
df = df.dropna(subset=['horsepower'], axis=0)                 # 누락데이터 행을 삭제
df['horsepower'] = df['horsepower'].astype('float')           # 문자열을 실수형으로 변환

# np.histogram 함수로 3개의 bin으로 나누는 경계 값의 리스트 구하기
count, bin_dividers = np.histogram(df['horsepower'], bins=3)
print(bin_dividers) 

>>>
[ 46.         107.33333333 168.66666667 230.        ]
# 4개의 경계값과 3개의 구간!!
```

```python
# 3개의 bin에 이름 지정
bin_names = ['저출력', '보통출력', '고출력']

# pd.cut 함수로 각 데이터를 3개의 bin에 할당
df['hp_bin'] = pd.cut(x=df['horsepower'],     # 데이터 배열
                      bins=bin_dividers,      # 경계 값 리스트
                      labels=bin_names,       # bin 이름
                      include_lowest=True)    # 첫 경계값 포함 

# horsepower 열, hp_bin 열의 첫 15행을 출력
df[['horsepower', 'hp_bin']].head(15)
```

![10.png](/assets/img/posts/PANDAS/part5/10.png)

### 더미 변수

카테고리를 나타내는 범주형 데이터를 회귀분석 등 머신러닝 알고리즘에 바로 사용할 수 없는 경우가 있는데, 컴퓨터가 인식 가능한 입력값으로 변환해야!!

→ 숫자 0 또는 1로 표현되는 **더미변수**를 사용

(해당 특성이 존재하면 1, 존재하지 않으면 0으로 구분하는 개념)

판다스 **`pd.get_dumies()`** 함수를 사용하면 범주형 변수의 모든 고유값을 각각 새로운 더미 변수로 변환한다

```python
# hp_bin 열의 범주형 데이터를 더미 변수로 변환 (dtype 지정)
horsepower_dummies_float = pd.get_dummies(df['hp_bin'], dtype=float)
horsepower_dummies_float.head()
```

![11.png](/assets/img/posts/PANDAS/part5/11.png)

## 정규화

숫자 데이터의 상대적인 크기 차이를 제거!!

정규화 과정을 거친 데이터의 범위는 0~1 또는 -1~1 이 됨

- Min-Max Scaling

![12.png](/assets/img/posts/PANDAS/part5/12.png)

```python
# horsepower 열의 통계 요약정보로 최대값(max)을 확인
df['horsepower'].describe()

>>>
count    392.000000
mean     104.469388
std       38.491160
min       46.000000
25%       75.000000
50%       93.500000
75%      126.000000
max      230.000000
Name: horsepower, dtype: float64

# horsepower 열을 Min-Max Scaling 적용 (판다스)
 df['horsepower_minmax'] = (df['horsepower'] - df['horsepower'].min()) / \
                          (df['horsepower'].max() - df['horsepower'].min()) 

# horsepower 열을 Min-Max Scaling 적용 (사이킷런)
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
df['horsepower_minmax'] = scaler.fit_transform(df[['horsepower']])

df['horsepower_minmax'].head()                          

>>>
0    0.456522
1    0.646739
2    0.565217
3    0.565217
4    0.510870
Name: horsepower_minmax, dtype: float64
```

- Standard Scaling

![13.png](/assets/img/posts/PANDAS/part5/13.png)

```python
# horsepower 열을 Standard Scaling 적용 (판다스)
df['horsepower_standard'] = (df['horsepower'] - df['horsepower'].mean()) / \
                             df['horsepower'].std()
                             
# horsepower 열을 Standard Scaling 적용 (사이킷런)
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
df['horsepower_standard'] = scaler.fit_transform(df[['horsepower']])

df['horsepower_standard'].head()

>>>
0    0.664133
1    1.574594
2    1.184397
3    1.184397
4    0.924265
Name: horsepower_standard, dtype: float64
```

## 시계열 데이터

시계열(time series) 데이터를 데이터프레임의 행 인덱스로 사용하면, 시간으로 기록된 데이터를 분석하는 것이 매우 편리함

![14.png](/assets/img/posts/PANDAS/part5/14.png)

- **Timestamp** : 특정 시점을 나타내는 값 (ex. 2024-08-08 12:34:56 과 같이 특정 날짜와 시간의 한 순간을 의미)
- **Period** : 일정한 시간 간격(기간)을 나타내는 값(ex. 2024-08 과 같이 ‘2024’년 ‘8’월 이라는 특정 기간을 의미)

### 문자열을 Timestamp 로 변환

판다스 **`pd.to_datetime()`** 함수를 사용하면 문자열 등 다른 자료형을 판다스 Timestamp를 나타내는 datetime64 자료형으로 변환 가능

```python
# 데이터 내용 및 자료형 자료형 확인
print(df.head())
print('\n')
print(df.info())
```

![15.png](/assets/img/posts/PANDAS/part5/15.png)

Date 열이 문자열로 설정되어 있으므로 to_datetime() 함수로 datetime64 자료형으로 변환

new_Date 를 type() 함수로 확인하면 Timestamp 객체임을 알 수 있음

```python
# 문자열 데이터(시리즈 객체)를 판다스 Timestamp로 변환
df['new_Date'] = pd.to_datetime(df['Date'])   #df에 새로운 열로 추가

# 시계열 값으로 변환된 열을 새로운 행 인덱스로 지정. 기존 날짜 열은 삭제
df = df.set_index('new_Date')
df = df.drop('Date', axis=1)

# 데이터 내용 및 자료형 자료형 확인
print(df.head())
print('\n')
print(df.info())
```

![16.png](/assets/img/posts/PANDAS/part5/16.png)

### Timestamp를 Period로 변환

판다스 **`pd.to_period()`** 함수를 이용하면 일정한 기간을 나타내는 Period 객체로 Timestamp 객체를 변환할 수 있음, **`freq`** 옵션에 기준이 되는 기간을 설정함(D : 1일, M : 1개월, A : 1년)

```python
# 날짜 형식의 문자열로 구성되는 리스트 정의
dates = ['2019-01-01', '2020-03-01', '2021-06-01']

# 문자열 데이터(시리즈 객체)를 판다스 Timestamp로 변환
ts_dates = pd.to_datetime(dates)   
print(ts_dates)

# Timestamp를 Period로 변환
pr_day = ts_dates.to_period(freq='D')
print(pr_day)
pr_month = ts_dates.to_period(freq='M')
print(pr_month)
pr_year = ts_dates.to_period(freq='Y')
print(pr_year)

>>>
DatetimeIndex(['2019-01-01', '2020-03-01', '2021-06-01'], dtype='datetime64[ns]', freq=None)
PeriodIndex(['2019-01-01', '2020-03-01', '2021-06-01'], dtype='period[D]')
PeriodIndex(['2019-01', '2020-03', '2021-06'], dtype='period[M]')
PeriodIndex(['2019', '2020', '2021'], dtype='period[Y-DEC]')
```

![17.png](/assets/img/posts/PANDAS/part5/17.png)

### Timestamp 배열 만들기

판다스 **`pd.date_range()`** 함수를 사용하면 여러 개의 날짜(Timestamp)가 들어 있는 배열 형태의 시계열 데이터를 만들 수 있음!!

```python
# Timestamp의 배열 만들기 - 월 간격, 월의 시작일 기준
ts_ms = pd.date_range(start='2024-01-01',    # 날짜 범위의 시작
                   end=None,                 # 날짜 범위의 끝
                   periods=6,                # 생성할 Timestamp의 개수
                   freq='MS',                # 시간 간격 (MS: 월의 시작일)
                   tz='Asia/Seoul')          # 시간대(timezone)

print(ts_ms)

>>>
DatetimeIndex(['2024-01-01 00:00:00+09:00', '2024-02-01 00:00:00+09:00',
               '2024-03-01 00:00:00+09:00', '2024-04-01 00:00:00+09:00',
               '2024-05-01 00:00:00+09:00', '2024-06-01 00:00:00+09:00'],
              dtype='datetime64[ns, Asia/Seoul]', freq='MS')
```

```python
# 분기(3개월) 간격, 월의 첫째 날 기준
ts_3m = pd.date_range('2024-01-01', periods=6, 
                       freq='3MS',             # 시간 간격 (3MS: 3개월)
                       tz='Asia/Seoul')        # 시간대(timezone)
print(ts_3m)

>>>
DatetimeIndex(['2024-01-01 00:00:00+09:00', '2024-04-01 00:00:00+09:00',
               '2024-07-01 00:00:00+09:00', '2024-10-01 00:00:00+09:00',
               '2025-01-01 00:00:00+09:00', '2025-04-01 00:00:00+09:00'],
              dtype='datetime64[ns, Asia/Seoul]', freq='3MS')
```

### Period 배열 만들기

판다스 **`pd.period_range()`** 함수는 여러 개의 기간(Period)이 들어 있는 시계열 데이터를 만들 수 있음!!

```python
# Period 배열 만들기 - 1개월 주기
pr_m = pd.period_range(start='2024-01-01',     # 날짜 범위의 시작
                   end=None,                   # 날짜 범위의 끝
                   periods=3,                  # 생성할 Period 개수
                   freq='M')                   # 주기 (M: 월)
print(pr_m)

>>>
PeriodIndex(['2024-01', '2024-02', '2024-03'], dtype='period[M]')
```

```python
# Period 배열 만들기 - 2일 주기
pr_2h = pd.period_range(start='2024-01-01',    # 날짜 범위의 시작
                   end=None,                   # 날짜 범위의 끝
                   periods=3,                  # 생성할 Period 개수
                   freq='2d')                  # 주기 (2d: 2일)
print(pr_2h)

>>>
PeriodIndex(['2024-01-01', '2024-01-03', '2024-01-05'], dtype='period[2D]')
```

### 날짜 데이터 분리

연-월-일 날짜 데이터에서 일부를 분리하여 추출 가능!

```python
< 연-월-일 정보를 연, 월, 일 각각으로 구분하기 >

# 문자열인 날짜 데이터를 판다스 Timestamp로 변환
df['new_Date'] = pd.to_datetime(df['Date'])   #df에 새로운 열로 추가

# dt 속성을 이용하여 new_Date 열의 년월일 정보를 년, 월, 일로 구분
df['Year'] = df['new_Date'].dt.year
df['Month'] = df['new_Date'].dt.month
df['Day'] = df['new_Date'].dt.day

df.head()
```

![18.png](/assets/img/posts/PANDAS/part5/18.png)

```python
# Timestamp를 Period로 변환하여 년월일 표기 변경하기
df['Date_yr'] = df['new_Date'].dt.to_period(freq='Y')
df['Date_m'] = df['new_Date'].dt.to_period(freq='M')
df.head()
```

![19.png](/assets/img/posts/PANDAS/part5/19.png)

### 날짜 인덱스 활용

Timestamp로 구성된 열을 행 인덱스로 지정하면 DatetimeIndex라는 고유 속성으로 변환됨

Period로 구성된 열을 행 인덱스로 지정하면 PeriodIndex라는 고유 속성으로 변환됨

날짜 인덱스를 활용하면 시계열 데이터에 대한 인덱싱과 슬라이싱이 편함

→ 연-월-일 중에서 내가 필요로 하는 레벨을 선택적으로 인덱싱 할 수 있음!

```python
# 부분 문자열 인덱싱 1
df.loc['2018-06-27']
```

![20.png](/assets/img/posts/PANDAS/part5/20.png)

```python
# 부분 문자열 인덱싱 2
df.loc['2018-07']
```

![21.png](/assets/img/posts/PANDAS/part5/21.png)

```python
# 부분 문자열 인덱싱 3
df.loc['2018-06-27':'2018-07-02']

# 시간 자료형을 활용한 인덱싱 1
df.loc[pd.Timestamp(2018, 6, 27):pd.Timestamp(2018, 7, 2)]  
```

![22.png](/assets/img/posts/PANDAS/part5/22.png)

```python
# 부분 문자열 인덱싱 4
df[df.index < '2018-06-05']
```

![23.png](/assets/img/posts/PANDAS/part5/23.png)