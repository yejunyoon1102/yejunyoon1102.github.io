---
layout: post
title: "머신러닝: 5.2 교차 검증과 그리드 서치"
date: 2024-08-16
categories: [Machine Learning, 5장]
---
# 5.2 교차 검증과 그리드 서치

<problem : 이런 저런 값으로 max_depth를 3말고 다른 값으로 해서 테스트 세트로 평가하면 결국 테스트 세트에 잘 맞는 모델이 만들어지는거 아닌가?>

테스트 세트로 일반화 성능을 올바르게 예측하려면 가능한 한 테스트 세트를 사용하지 말아야 겠는데..? 모델을 만들고 나서 마지막에 딱 한번 사용하는 게 좋겠네..!! 

### 검증 세트

테스트 세트를 사용하지 않고 모델이 과대적합인지 과소적합인지 판단하려면 훈련 세트를 또 나누는 방법 !!! → 이 데이터를 **검증 세트**라고 부름

![1.png](/assets/img/posts/ML/ML5.2/1.png)

보통 20~30% 정도를 테스트 세트와 훈련 세트로 떼어 놓음!!

1. 훈련 세트에서 모델을 훈련하고 검증 세트로 모델을 평가!!
2. 테스트하고 싶은 매개변수를 바꿔가며 가장 좋은 모델을 고름
3. 그 다음 이 매개변수를 사용해서 훈련 세트와 검증 세트를 합쳐 전체 훈련 데이터에서 모델을 다시 훈련시킴
4. 마지막에 테스트 세트에서 최종 점수를 평가

```python
# 데이터 불러오기

import pandas as pd

wine = pd.read_csv('https://bit.ly/wine_csv_data')
```

```python
# class 열을 타깃으로 사용하고 나머지는 특성 배열에 저장

data = wine[['alcohol', 'sugar', 'pH']].to_numpy()
target = wine['class'].to_numpy()
```

```python
# 훈련 세트와 테스트 세트를 나눔

from sklearn.model_selection import train_test_split

train_input, test_input, train_target, test_target = train_test_split(
    data, target, test_size=0.2, random_state=42)
```

훈련 세트(train_input 과 train_target을 다시 train_test_split() 함수에 넣어 검증 세트로 나눔!!

```python
# 훈련 세트와 검증 세트를 나눔(20%)

sub_input, val_input, sub_target, val_target = train_test_split(
    train_input, train_target, test_size=0.2, random_state=42)
```

```python
# 훈련 세트와 검증 세트 크기 확인

print(sub_input.shape, val_input.shape)

>>>
(4157, 3) (1040, 3)
```

원래 5197개였던 훈련 세트가 4157개로 줄고 검증 세트는 1040개가 되었네!!

```python
# 훈련 세트와 검증 세트를 사용해 모델 만들고 평가

from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier(random_state=42)
dt.fit(sub_input, sub_target)

print(dt.score(sub_input, sub_target))
print(dt.score(val_input, val_target))

>>>

0.9971133028626413
0.864423076923077
```

훈련 세트에 과대적합 되어있네.. 매개변수를 바꾸어 더 좋은 모델을 찾자!!

### 교차 검증

검증 세트를 만드느라 훈련 세트가 줄었는데..

보통 많은 데이터를 훈련에 쓰면 좋은 모델이 만들어지지 않나???

그렇다고 검증 세트를 너무 조금 떼어 놓으면 기복이 심해지는데..?

→ **교차 검증**을 이용하면 안정적인 검증 점수를 얻고 훈련에 더 많은 데이터 사용

- **k-폴드 교차 검증**

검증 세트를 떼어 내어 평가하는 과정을 여러 번 반복!!

![2.png](/assets/img/posts/ML/ML5.2/2.png)

훈련 세트를 몇 부분으로 나누냐에 따라 다르게 부름!! (여기선 3-폴드 교차 검증)

보통 5-폴드 교차 검증이나 10-폴드 교차 검증을 많이 사용!!!

사이킷런의 **`cross_validate()`** 라는 교차 검증 함수 사용

평가할 모델 객체를 첫 번째 매개변수로 전달!! 훈련 세트 전체를 뒤에 전달

```python
# 교차 검증 함수 사용 (기본값 : 5-폴드 교차 검증)

from sklearn.model_selection import cross_validate

scores = cross_validate(dt, train_input, train_target)
print(scores)

>>>
{'fit_time': array([0.00931716, 0.00749564, 0.00773239, 0.00731683, 0.00710797]), 'score_time': array([0.00109315, 0.00111032, 0.00101209, 0.00106931, 0.00115085]), 'test_score': array([0.86923077, 0.84615385, 0.87680462, 0.84889317, 0.83541867])}
```

**`fit_time`** : 모델을 훈련하는 시간

**`score_time`** : 모델을 검증하는 시간

**`test_score`** : 검증 폴드의 점수 → 최종 점수는 평균 내서 구할 수 있음!!

```python
# 교차 검증 점수 확인

import numpy as np

print(np.mean(scores['test_score']))

>>>
0.855300214703487
```

주의) **`cross_validate()`** 함수는 훈련 세트를 섞어 폴드를 나누지 않음!!

여기서는 앞서 **`train_test_split()`** 함수로 섞어서 준비했기 때문에 따로 섞을 필요X

만약 교차 검증에서 훈련 세트를 섞으려면 **분할기** 지정!!

사이킷런의 분할기는 교차 검증에서 폴드를 어떻게 나눌지 결정해줌!!

**`cross_validate()`** 함수는 기본적으로 **회귀 모델**일 경우 **KFold 분할기**를 사용하고 **분류 모델**일 경우 **StratifiedKFold 분할기** 사용!!

```python
# 분류 모델 분할기 지정

from sklearn.model_selection import StratifiedKFold

scores = cross_validate(dt, train_input, train_target, cv=StratifiedKFold())
print(np.mean(scores['test_score']))

>>>
0.855300214703487
```

**`n_splits`** 매개변수는 몇(k) 폴드 교차 검증 할지 지정!!

```python
# 10-폴드 교차 검증

splitter = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)
scores = cross_validate(dt, train_input, train_target, cv=splitter)
print(np.mean(scores['test_score']))

>>>
0.8574181117533719
```

이제 결정 트리의 매개변수 값을 바꿔가며 가장 좋은 성능이 나오는 모델 찾자..!

이때 테스트 세트를 사용하지 않고 교차 검증을 사용하자!!!

### 하이퍼파라미터 튜닝

- 머신러닝 모델이 학습하는 파라미터 : **모델 파라미터**
- 모델이 학습할 수 없어 사용자가 지정해야만 하는 파라미터 : **하이퍼파라미터**

HOW 튜닝..?

먼저 라이브러리가 제공하는 기본값을 그대로 사용, 검증 세트의 점수나 교차 검증을 통해 매개변수를 조금씩 바꿔보기!!

주의) 매개변수 사이의 연관성이 있기 때문에 하나씩 최적값을 찾지 말고 동시에!!

사이킷런의 **`GridSearchCV`** 클래스는 하이퍼파라미터 탐색과 교차 검증을 한번에 수행!! (별도로 cross_validate() 함수 호출 할 필요 X)

```python
# 탐색할 매개변수와 탐색할 값의 리스트를 딕셔너리로 만들기

from sklearn.model_selection import GridSearchCV

params = {'min_impurity_decrease': [0.0001, 0.0002, 0.0003, 0.0004, 0.0005]}
```

```python
# GridSearchCV 클래스에 탐색 대상 모델과 params 변수 전달해서 그리드 서치 객체 만들기

gs = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1)
```

GridSearchCV의 cv 매개변수 기본값은 5 (5-폴드 교차 검증 수행)

**`n_jobs`** 매개변수에서 병렬 실행에 사용할 CPU 코어 수 지정(기본값 1)

→ -1로 지정하면 시스템에 있는 모든 코어를 사용함!!

**`fit()`** 메소드 호출하면 결정 트리 모델min_impurity_decrease 값을 바꿔가며 5번 실행!!

```python
# 그리드 서치 수행

gs.fit(train_input, train_target)
```

사이킷런의 그리드 서치는 훈련이 끝나면 25개의 모델 중에 검증 점수가 가장 높은 모델의 매개변수 조합으로 전체 훈련 세트에서 자동으로 모델 다시 훈련!!!

→ 이 모델은 **`gs.best_estimator_`** 속성에 저장 되어 있음!!

```python
# 검증 점수가 가장 높은 매개변수 조합으로 모델 훈련시킨 결과 확인

dt = gs.best_estimator_
print(dt.score(train_input, train_target))

>>>
0.9615162593804117
```

그리드 서치로 찾은 최적의 매개변수는**`best_params_`** 속성에 저장

```python
# 최적의 매개변수 확인

print(gs.best_params_)

>>>
{'min_impurity_decrease': 0.0001}
```

각 매개변수에서 수행한 교차 검증의 평균 점수는 **`cv_results_`** 속성의 **`‘mean_test_score’`** 키에 저장되어 있음!!

```python
# 각 매개변수에서 수행한 교차 검증의 평균 점수 확인

print(gs.cv_results_['mean_test_score'])

>>>
[0.86819297 0.86453617 0.86492226 0.86780891 0.86761605]
```

뭐가 제일 크지..? 소수점 눈아파… 

→ **`np.argmax()`** 함수를 사용하면 가장 큰 값의 인덱스 추출 가능!!! 

그 다음 이 인덱스를 사용해 params 키에 저장된 매개변수 출력 가능

```python
# 가장 큰 값의 인덱스 사용해서 어떤 매개변수인지 출력

best_index = np.argmax(gs.cv_results_['mean_test_score'])
print(gs.cv_results_['params'][best_index])

>>>
{'min_impurity_decrease': 0.0001}
```

음… **`best_params_`** 속성으로 봤던거랑 같군…

이번엔 min_impurity_decrease, max_depth, min_samples_split 매개변수 같이 서치 해보자!

```python
# 탐색할 매개변수와 탐색할 값의 리스트를 딕셔너리로 만들기

params = {'min_impurity_decrease': np.arange(0.0001, 0.001, 0.0001),
          'max_depth': range(5, 20, 1),
          'min_samples_split': range(2, 100, 10)
          }
```

검증할 모델의 수는 6750개나 되니까 n_jobs 매개변수 -1로 설정해야겠네…

```python
# 그리드 서치 수행

gs = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1)
gs.fit(train_input, train_target)
```

```python
# 최상의 매개변수 조합 확인

print(gs.best_params_)

>>>
{'max_depth': 14, 'min_impurity_decrease': 0.0004, 'min_samples_split': 12}
```

```python
# 최상의 교차 검증 점수 확인

print(np.max(gs.cv_results_['mean_test_score']))

>>>
0.8683865773302731
```

매개변수 값의 간격을 멋있게 수행할 수 없을까..?

### 랜덤 서치

매개변수의 값이 수치일 때 값의 범위나 간격을 미리 정하기 어려워요…

이럴 때 **랜덤 서치** 이용!!!!

랜덤 서치에는 매개변수 값의 목록을 전달하는 것이 아니라 매개변수를 샘플링할 수 있는 확률 분포 객체를 전달함!!

```python
# 싸이파이에서 2개의 확률 분포 클래스 임포트

from scipy.stats import uniform, randint
```

**`uniform`** 클래스 : 주어진 범위에서 고르게 값(**실수값**)을 뽑음

**`radiant`** 클래스 : 주어진 범위에서 고르게 값(**정수값**)을 뽑음 

```python
# 0에서 10사이의 범위를 갖는 radiant 객체에서 10개 숫자 샘플링

rgen = randint(0, 10)
rgen.rvs(10)

>>>
array([4, 7, 6, 8, 9, 3, 8, 3, 1, 4])

# 샘플링 숫자를 늘려 확인

np.unique(rgen.rvs(1000), return_counts=True)

>>>
(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),
 array([116, 105,  95, 100,  84,  90,  97,  95, 107, 111]))
```

```python
# 0에서 1 사이의 법위를 갖는 uniform 객체에서 10개 숫자 샘플링

ugen = uniform(0, 1)
ugen.rvs(10)

>>>
array([0.07156624, 0.51330724, 0.78244744, 0.14237963, 0.05055468,
       0.13124955, 0.15801332, 0.99110938, 0.08459786, 0.92447632])
```

난수 발생기랑 유사한 느낌!!

min_impurity_decrease, max_depth, min_samples_split, min_samples_leaf 매개변수로 같이 랜덤 서치 해보자!!

```python
# 탐색할 매개변수와 탐색할 값의 리스트를 딕셔너리로 만들기

params = {'min_impurity_decrease': uniform(0.0001, 0.001),
          'max_depth': randint(20, 50),
          'min_samples_split': randint(2, 25),
          'min_samples_leaf': randint(1, 25),
          }
```

```python
# 랜덤 서치 수행

from sklearn.model_selection import RandomizedSearchCV

gs = RandomizedSearchCV(DecisionTreeClassifier(random_state=42), params,
                        n_iter=100, n_jobs=-1, random_state=42)
gs.fit(train_input, train_target)
```

샘플링 횟수는 **`n_iter`** 매개변수 사용!!

```python
# 최상의 매개변수 조합 확인

print(gs.best_params_)

>>>
{'max_depth': 39, 'min_impurity_decrease': 0.00034102546602601173, 'min_samples_leaf': 7, 'min_samples_split': 13}
```

```python
# 최상의 교차 검증 점수 확인

print(np.max(gs.cv_results_['mean_test_score']))

>>>
0.8695428296438884
```

```python
# 이 모델을 최종 모델로 결정하고 테스트 세트 성능 확인

dt = gs.best_estimator_

print(dt.score(test_input, test_target))

>>>
0.86
```

앞으로는 수동으로 매개변수 바꾸지 말고 **그리드 서치**나 **랜덤 서치** 사용합시다!!