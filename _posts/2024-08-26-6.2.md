---
layout: post
title: "머신러닝 : 6.2 k-평균"
date: 2024-08-26
categories: [Machine Learning, 6장]
---
# 6.2 k-평균

< problem : 타겟값을 모를때는 각 픽셀의 평균을 어떻게 구하려나? → k-평균 군집 알고리즘이 있지!! 이 평균값이 클러스터의 중심에 위치하기 때문에 클러스터 중심 / 센트로이드 라고 부름!!>

### k-평균 알고리즘 소개

작동방식

1. 무작위로 k개의 클러스터 중심을 정함
2. 각 샘플에서 가장 가까운 클러스터 중심을 찾아 해당 클러스터의 샘플로 지정
3. 클러스터에 속한 샘플의 평균값으로 클러스터 중심을 변경
4. 클러스터 중심에 변화가 없을 때까지 2번으로 돌아가 반복

![1.png](/assets/img/posts/ML/ML6.2/1.png)

### KMeans 클래스

k-평균 모델을 훈련하기 위해 (샘플 개수, 너비, 높이) 크기의 3차원 배열을 (샘플 개수, 너비x높이) 크기의 2차원 배열로 변경!!

```python
# 데이터 다운로드, 차원 변경

!wget https://bit.ly/fruits_300_data -O fruits_300.npy
import numpy as np

fruits = np.load('fruits_300.npy')
fruits_2d = fruits.reshape(-1, 100*100)
```

사이킷런의 k-평균 알고리즘은 **`sklearn.cluster`** 모듈 아래 **`KMeans`** 클래스에 구현!

**`n_clusters`** : 클러스터 개수를 지정

비지도 학습이니까 fit() 메서드에 타깃 데이터 사용하지 않음!!!

```python
# k-평균 알고리즘 학습

from sklearn.cluster import KMeans

km = KMeans(n_clusters=3, random_state=42)
km.fit(fruits_2d)
```

군집된 결과는 KMeans 클래스 객체의 **`labels_`** 속성에 저장됨!!

labels_ 길이는 샘플 개수로 각 샘플이 어떤 레이블에 해당되는지 나타냄!

```python
# 레이블 확인

print(km.labels_)

>>>
[2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 0 2 0 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 0 0 2 2 2 2 2 2 2 2 0 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1]

```

레이블값 0, 1, 2와 레이블 순서는 아무런 연관 X!

실제 레이블 0, 1, 2가 어떤 과일 사진인지는 직접 이미지를 출력하는 수 밖에

그 전에 레이블 0, 1, 2로 모은 샘플의 개수 확인

```python
# 샘플 개수 확인

print(np.unique(km.labels_, return_counts=True))

>>>
(array([0, 1, 2], dtype=int32), array([111,  98,  91]))
```

첫 번째 클러스터(레이블0)이 91개의 샘플, 두 번째 클러스터(레이블1)은 98개, 세 번째 클러스터(레이블2)은 111개 모았네!

각 클러스터가 어떤 이미지를 나타낸건지 그림으로 출력하자

```python
import matplotlib.pyplot as plt

def draw_fruits(arr, ratio=1):
    n = len(arr)    # n은 샘플 개수입니다
    # 한 줄에 10개씩 이미지를 그립니다. 샘플 개수를 10으로 나누어 전체 행 개수를 계산합니다.
    rows = int(np.ceil(n/10))
    # 행이 1개 이면 열 개수는 샘플 개수입니다. 그렇지 않으면 10개입니다.
    cols = n if rows < 2 else 10
    fig, axs = plt.subplots(rows, cols,
                            figsize=(cols*ratio, rows*ratio), squeeze=False)
    for i in range(rows):
        for j in range(cols):
            if i*10 + j < n:    # n 개까지만 그립니다.
                axs[i, j].imshow(arr[i*10 + j], cmap='gray_r')
            axs[i, j].axis('off')
    plt.show()
```

레이블이 0인 과일 사진 그리려면 km.labels_ == 0과 같이 쓰면 값이 0인 위치는 True, 그 외에는 False가 됨 → **불리언 인덱싱!!**

```python
# 레이블 0 출력

draw_fruits(fruits[km.labels_==0])
```

![2.png](/assets/img/posts/ML/ML6.2/2.png)

음.. 사과가 잘 모였네

```python
# 레이블 1 출력

draw_fruits(fruits[km.labels_==1])
```

![3.png](/assets/img/posts/ML/ML6.2/3.png)

```python
# 레이블 2 출력

draw_fruits(fruits[km.labels_==2])
```

![4.png](/assets/img/posts/ML/ML6.2/4.png)

레이블 1인 클러스터는 바나나로 잘 이루어진 거 같은데…

레이블 2인 클러스터는 파인애플에 사과 9개랑 바나나 2개가 섞여있네..

완벽하진 않았나보네!

### 클러스터 중심

KMeans 클래스가 최종적으로 찾은 클러스터 중심은 **`cluser_centers_`** 속성에 저장되어 있음!!

이 배열은 fruits_2d 샘플의 클러스터 중심이기 때문에 이미지로 출력하려면 100x100 크기의 2차원 배열 필요!!

```python
# 2차원 배열 확인

draw_fruits(km.cluster_centers_.reshape(-1, 100, 100), ratio=3)
```

![5.png](/assets/img/posts/ML/ML6.2/5.png)

이전 절에서 사과, 바나나, 파인애플의 픽셀 평균값 출력이랑 비슷한데..?

KMeans 클래스는 훈련 데이터 샘플에서 클러스터 중심까지 거리로 변환해주는 **`transform()`** 메서드가 있음! → StandardScaler 클래스처럼 특성값을 변환하는 도구로 사용 가능

인덱스가 100인 샘플에 transform() 적용해볼까..?

```python
# 인덱스 100인 샘플의 거리 확인

print(km.transform(fruits_2d[100:101]))

>>>
[[5267.70439881  8837.37750892 3393.8136117]]
```

첫 번째 클러스터(레이블0)가 첫 번째 원소, 두 번째 클러스터(레이블1)가 두 번 째 원소, 세 번째 클러스터(레이블2)가 세 번째 원소값!!

→ 흠.. 세 번째 클러스터까지의 거리가 가장 작네

KMeans 클래스는 가장 가까운 클러스터 중심을 예측 클래스로 출력하는 **`predict()`** 메서드도 있음!!

```python
# 가장 가까운 클러스터 중심 예측

print(km.predict(fruits_2d[100:101]))

>>>
[2]
```

레이블 2로 예측했네!! 클러스터 중심을 시각화했을 때 파인애플이었으니까..

```python
# 인덱스 100인 샘플의 이미지 시각화

draw_fruits(fruits[100:101])
```

![6.png](/assets/img/posts/ML/ML6.2/6.png)

KMeans 클래스는 반복적으로 클러스터 중심을 옮기면서 최적의 클러스터를 찾는데 반복한 횟수를 반환하는 **`n_iter_`** 속성에 저장!!

```python
# 반복한 횟수 반환

print(km.n_iter_)

>>>
3
```

사실 n_clusters을 3으로 지정했기 때문에 좀 야매긴 하지..!

실전에서 최적의 클러스터 개수는 어떻게 찾을까?

### 최적의 k 찾기

k-평균 알고리즘의 단점 중 하나는 클러스터 개수를 사전에 지정해야 한다는 것!

적절한 클러스터 개수를 찾기 위한 대표적 방법 → **엘보우 방법**

k-평균 알고리즘에서 클러스터 중심과 클러스터에 속한 샘플 사이의 거리를 잴 수 있고, 이 거리의 제곱 합을 **이너셔**라고 함!!!

→ 클러스터에 속한 샘플이 얼마나 가깝게 모여 있는지를 나타내는 값

일반적으로 클러스터 개수가 늘어나면 이너셔도 줄어들겠지!

클러스터 개수를 증가시키면서 이너셔를 그래프로 그리면 감소하는 속도가 꺾이는 지점이 존재 → 이 지점부터는 클러스터 개수를 늘려도 클러스터에 잘 밀집된 정도가 크게 개선 X → 이너셔가 크게 줄어들지 않음!!

![7.png](/assets/img/posts/ML/ML6.2/7.png)

KMeans 클래스는 자동으로 이너셔를 계산해서 **`inertia_`** 속성으로 저장!!

클러스터 개수 k를 2~6까지 바꿔가면서 KMeans 클래스를 5번 훈련하자!

```python
# k 값을 2~6 바꿔가면서 반복 훈련

inertia = []
for k in range(2, 7):
    km = KMeans(n_clusters=k, n_init='auto', random_state=42)
    km.fit(fruits_2d)
    inertia.append(km.inertia_)

plt.plot(range(2, 7), inertia)
plt.xlabel('k')
plt.ylabel('inertia')
plt.show()
```

![8.png](/assets/img/posts/ML/ML6.2/8.png)

흠.. k=3 에서 그래프의 기울기가 조금 바뀐거 같긴 하네..!

엘보우 지점보다 클러스터 개수가 많아지면 이너셔의 변화가 줄어들면서 군집 효과도 줄어듦!