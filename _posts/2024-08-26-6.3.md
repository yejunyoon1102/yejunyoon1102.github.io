---
layout: post
title: "머신러닝 : 6.3 주성분 분석"
date: 2024-08-26
categories: [Machine Learning, 6장]
---
# 6.3 주성분 분석

< problem : 너무 많은 사진이 등록되서 저장 공간이 부족한데… 나중에 군집이나 분류에 영향을 끼치지 않으면서 업로드된 사진의 용량을 줄일 수 없을까? >

### 차원과 차원 축소

지금까지는 데이터가 가진 속성을 특성이라 불렀음

과일 사진의 경우 10000개의 픽셀이 있기 때문에 10000개의 특성이 있는 셈!

→ 머신러닝에서는 이런 특성을 **차원** 이라고도 부름!!!

- 우리가 쓰는 1차원 배열 2차원 배열 이거랑 다른건가..?

→ 다차원 배열에서 차원은 배열의 축 개수를 의미함!! 가령 2차원 배열일 때는 행과 열이 차원이 되고, 1차원 배열(벡터)일 경우에는 원소의 개수를 의미!!

이를 위해 비지도 학습 작업 중 하나인 **차원 축소 알고리즘**을 알아보자!!

차원 축소는 데이터를 가장 잘 나타내는 일부 특성을 선택하여 데이터 크기를 줄이고 지도 학습 모델의 성능을 향상시킬 수 있는 방법!!

또한 줄어든 차원에서 다시 원본 차원으로 손실을 최대한 줄이면서 복원도 가능!

대표적 차원 축소 알고리즘 → **주성분 분석(PCA)**

### 주성분 분석 소개

주성분 분석(PCA)은 데이터에 있는 분산이 큰 방향을 찾는 것!

→ 분산은 데이터가 널리 퍼져 있는 정도를 말함

→ 분산이 큰 방향을 데이터로 잘 표현하는 벡터로 표현 가능

![1.png](/assets/img/posts/ML/ML6.3/1.png)

이 데이터는 x1, x2 2개의 특성이 있음! 가장 분산이 큰 방향은 어디일까?

![2.png](/assets/img/posts/ML/ML6.3/2.png)

직관적으로 길게 늘어진 대각선 방향이 제일 큰 것 같은데??

앞에서 찾은 직선이 원점에서 출발한다면 두 원소로 이루어진 벡터로 쓸 수 있겠네!

![3.png](/assets/img/posts/ML/ML6.3/3.png)

이 벡터를 **주성분** 이라고 부름!!

주성분 벡터의 원소 개수는 원본 데이터셋에 있는 특성 개수와 같음!!

하지만 원본 데이터는 주성분을 사용해 차원을 줄일 수 있음

예를 들어 s(4, 2)를 주성분에 직각으로 투영하면 1차원 데이터(p4, 5)를 만들 수 있음

![4.png](/assets/img/posts/ML/ML6.3/4.png)

주성분은 원본 차원과 같고 주성분으로 바꾼 데이터는 차원이 줄어든다는 점을 꼭 기억하자!!!!

주성분이 가장 분산이 큰 방향이기 때문에 주성분에 투영하여 바꾼 데이터는 원본이 가지고 있는 특성을 가장 잘 나타내고 있을 것!

→ 첫 번째 주성분을 찾은 다음 이 벡터에 수직이고 분산이 가장 큰 다음 방향을 찾으면 그 벡터가 두 번째 주성분!!

![5.png](/assets/img/posts/ML/ML6.3/5.png)

일반적으로 주성분은 원본 특성의 개수만큼 찾을 수 있음!!

### PCA 클래스

```python
# 데이터 다운, 넘파이 배열로 적재

!wget https://bit.ly/fruits_300_data -O fruits_300.npy
import numpy as np

fruits = np.load('fruits_300.npy')
fruits_2d = fruits.reshape(-1, 100*100)
```

사이킷런은 **`sklearn.decomposition`** 모듈 아래 **`PCA`** 클래스로 주성분 분석 알고리즘을 제공!!

PCA 클래스의 객체를 만들 때 **`n_componenets`** 매개변수에 주성분의 개수를 지정해야 함!

비지도 학습이므로 fit() 메서드에 타깃값 제공 X

```python
# PCA 학습

from sklearn.decomposition import PCA

pca = PCA(n_components=50)
pca.fit(fruits_2d)
```

```python
# 주성분의 크기 확인

print(pca.components_.shape)

>>>
(50, 10000)
```

주성분을 50개로 지정했기 때문에 pca.components_ 배열의 첫 번째 차원이 50이고 두 번째 차원은 항상 원본 데이터의 특성 개수와 같은 10000!!

원본 데이터와 같으므로 주성분을 100 x 100 크기의 이미지처럼 출력 가능!

```python
# 이미지 출력 함수 만들기

import matplotlib.pyplot as plt

def draw_fruits(arr, ratio=1):
    n = len(arr)    # n은 샘플 개수입니다
    # 한 줄에 10개씩 이미지를 그립니다. 샘플 개수를 10으로 나누어 전체 행 개수를 계산합니다.
    rows = int(np.ceil(n/10))
    # 행이 1개 이면 열 개수는 샘플 개수입니다. 그렇지 않으면 10개입니다.
    cols = n if rows < 2 else 10
    fig, axs = plt.subplots(rows, cols,
                            figsize=(cols*ratio, rows*ratio), squeeze=False)
    for i in range(rows):
        for j in range(cols):
            if i*10 + j < n:    # n 개까지만 그립니다.
                axs[i, j].imshow(arr[i*10 + j], cmap='gray_r')
            axs[i, j].axis('off')
    plt.show()
```

```python
# 주성분을 그림으로 시각화

draw_fruits(pca.components_.reshape(-1, 100, 100))
```

![6.png](/assets/img/posts/ML/ML6.3/6.png)

이 주성분은 원본 데이터에서 가장 분산이 큰 방향을 순서대로 나타낸 것인데…

데이터셋에 있는 어떤 특징을 잡아낸 것인가?

→ 주성분을 찾았으므로 원본 데이터를 주성분에 투영하여 특성의 개수를 10000개에서 50개로 줄일 수 있음!! → 마치 원본 데이터를 각 주성분으로 분해하는 것

**`transform()`** 메서드 이용해서 차원 축소 가능!

```python
# 현재 차원 확인

print(fruits_2d.shape)

>>>
(300, 10000)
```

```python
# 차원 축소 후 차원 확인

fruits_pca = pca.transform(fruits_2d)
print(fruits_pca.shape)

>>>
(300, 50)
```

fruits_2d는 10000개의 특성을 가진 300개의 이미지였는데 PCA를 이용하니 50개의 특성으로 줄어듦!

데이터의 차원을 줄였다면 원상 복구도 가능한가..?

### 원본 데이터 재구성

앞에서 10000개의 특성을 50개로 줄였는데 이로 인해 어느 정도 손실이 발생할 수는 있지!

하지만 최대한 분산이 큰 방향으로 투영했기 때문에 원본 데이터를 상당 부분 재구성 할 수 있음

PCA클래스는 이를 위해 inverse_transform() 메서드를 제공

```python
# 다시 10000개의 특성으로 복원

fruits_inverse = pca.inverse_transform(fruits_pca)
print(fruits_inverse.shape)

>>>
(300, 10000)

```

이 데이터를 100 x 100 크기로 바꾸어 100개씩 나누어 출력!

```python
# 100 x 100 크기로 출력

fruits_reconstruct = fruits_inverse.reshape(-1, 100, 100)
for start in [0, 100, 200]:
    draw_fruits(fruits_reconstruct[start:start+100])
    print("\n")
```

![7.png](/assets/img/posts/ML/ML6.3/7.png)

모든 과일이 잘 복원되었네!

일부 흐리고 번진 부분이 있지만 불과 50개의 특성을 10000개로 늘린 것을 감안하면 좋은데!?!?

→ 이 50개의 특성이 분산을 가장 잘 보존하도록 변환된 것이기 때문

50개의 특성은 얼마나 분산을 보존하고 있길래..?

### 설명된 분산

주성분이 원본 데이터의 분산을 얼마나 잘 나타내는지 기록한 값을 **설명된 분산**이라고 함!

PCA 클래스의 **`explained_variance_ratio_`**에 각 주성분의 설명된 분산 비율이 기록되어 있음

당연히 첫 번째 주성분의 설명된 분산이 제일 크고 이 분산 비율을 모두 더하면 50개의 주성분으로 표현하고 있는 총 분산 비율을 얻을 수 있음!!

```python
# 설명된 분산값 확인

print(np.sum(pca.explained_variance_ratio_))

>>>
0.9215651897863715
```

92%가 넘는 분산을 유지하고 있네..!

설명된 분산의 비율을 그래프로 그려보면 적절한 주성분의 개수를 찾는 데 도움이 됨

```python
# 설명된 분산의 비율 그래프로 그리기

plt.plot(pca.explained_variance_ratio_)
```

![8.png](/assets/img/posts/ML/ML6.3/8.png)

처음 10개의 주성분이 대부분의 분산을 표현하고 있네!!

이번에는 PCA로 차원 축소된 데이터를 사용해서 지도학습 모델을 훈련시켜서 원본 데이터를 사용했을 때와 어떤 차이가 있는지 확인해보자!

### 다른 알고리즘과 함께 사용하기

3개의 과일 사진을 분류해야 하므로 간단히 로지스틱 회귀 모델 사용!

```python
# 로지스틱 회귀 모델 만들기

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()
```

지도 학습 모델을 사용하려면 타깃값이 있어야 함!

여기서는 사과를 0, 파인애플을 1, 바나나를 2로 지정

```python
# 타깃값 만들기

target = np.array([0] * 100 + [1] * 100 + [2] * 100)
```

원본 데이터인 fruits_2d 사용, 로지스틱 회귀 모델에서 성능을 가늠해보기 위해 교차 검증 수행

```python
# 교차 검증 수행

from sklearn.model_selection import cross_validate

scores = cross_validate(lr, fruits_2d, target)
print(np.mean(scores['test_score']))
print(np.mean(scores['fit_time']))

>>>
0.9966666666666667
0.9422160625457764
```

교차 검증 점수가 0.997정도로 매우 높네..!

특성이 10000개나 되니까 300개의 샘플에서는 과대적합된 모델을 만들기가 쉽네

**`cross_validate()`** 함수가 반환하는 딕셔너리에서는 **`fit_time`** 항목에 각 교차 검증 폴드의 훈련시간이 있음! → 0.94초 정도 걸렸네..

이 값을 PCA로 축소한 fruits_pca를 사용했을 때와 비교해보자!

```python
# PCA로 축소된 데이터의 교차 검증 수행

scores = cross_validate(lr, fruits_pca, target)
print(np.mean(scores['test_score']))
print(np.mean(scores['fit_time']))

>>>
1.0
0.032833099365234375
```

50개의 특성만 사용했는데도 정확도가 100%고 훈련시간이 0.03초라고..?

PCA로 훈련 데이터의 차원을 축소하면 저장 공간 뿐만 아니라 머신러닝 모델의 훈련 속도도 높이네!

앞서 n_components 매개변수에 주성분의 개수를 저장했는데 이 대신에 원하는 설명된 분산의 비율을 입력할 수도 있음!!! → PCA 클래스는 지정된 비율에 도달할 때까지 자동으로 주성분을 찾음

**`n_components`** 매개변수에 개수 대신 0~1 사이의 비율을 실수로 입력!!!

```python
# 설명된 분산의 50%에 달하는 주성분을 찾도록 PCA 모델 만들기

pca = PCA(n_components=0.5)
pca.fit(fruits_2d)
```

```python
# 몇 개의 주성분을 찾았는지 확인

print(pca.n_components_)

>>>
2
```

2개의 특성만으로도 원본 데이터에 있는 분산의 50%를 표현할 수 있다고!?!?

이 모델로 원본 데이터를 변환하자!

```python
# 원본 데이터 변환

fruits_pca = pca.transform(fruits_2d)
print(fruits_pca.shape)

>>>
(300, 2)
```

주성분이 2개이므로 변환된 데이터의 크기는 (300, 2)가 되네!

교차 검증의 결과는 어떨까?

```python
# 교차 검증 수행

scores = cross_validate(lr, fruits_pca, target)
print(np.mean(scores['test_score']))
print(np.mean(scores['fit_time']))

>>>
0.9933333333333334
0.03713240623474121
```

2개의 특성을 사용했는데도 99%의 정확도라고..?

이번엔 차원 축소된 데이터를 사용해 k-평균 알고리즘으로 클러스터 찾아볼까..?

```python
# k-평균 알고리즘으로 클러스터 출력

from sklearn.cluster import KMeans

km = KMeans(n_clusters=3, random_state=42)
km.fit(fruits_pca)
print(np.unique(km.labels_, return_counts=True))

>>>
(array([0, 1, 2], dtype=int32), array([110,  99,  91]))
```

각각 91개, 99개, 110개의 샘플을 포함하네!!

KMeans가 찾은 레이블을 사용해 과일 이미지를 출력해볼까?

```python
# 레이블 이미지 출력

for label in range(0, 3):
    draw_fruits(fruits[km.labels_ == label])
    print("\n")
```

![9.png](/assets/img/posts/ML/ML6.3/9.png)

2절에서 찾은 것이랑 비슷하네..

훈련 데이터의 차원을 줄이면 또 하나 얻을 수 있는 장점은 시각화!!

→ 3개 이하로 차원을 줄이면 화면에 출력하기 비교적 쉬움

```python
# 각 클러스터별로 산점도 그리기

for label in range(0, 3):
    data = fruits_pca[km.labels_ == label]
    plt.scatter(data[:,0], data[:,1])
plt.legend(['apple', 'banana', 'pineapple'])
plt.show()
```

![10.png](/assets/img/posts/ML/ML6.3/10.png)

아주 잘 구분되네..!