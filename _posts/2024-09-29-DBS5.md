---
layout: post
title: "데이터 분석 : 파이썬 데이터 분석 실무 테크닉 100 5장"
date: 2024-09-29
categories: [Data Analysis, Technique]
---
# 5장 : 회원 탈퇴를 예측하는 테크닉 10

이미 탈퇴한 회원과 계속해서 이용하는 회원의 데이터를 가지고 ‘의사결정 트리’ 알고리즘을 이용해서 탈퇴를 예측하는 흐름!

→ 간단하지만, 알기 쉽게 원인 분석을 할 수 있어 실무에서 자주 사용

Object : 회원을 정착시키고 늘려가는 것보다 탈퇴를 막는 게 더 중요한거 같은데… 왜 탈퇴했고 예측할 수 있을까?

![1.png](/assets/img/posts/DBS/DBS%205/1.png)

### 1. 데이터를 읽어 들이고 이용 데이터를 수정하자

```python
# 데이터 불러오기

import pandas as pd
customer = pd.read_csv('customer_join.csv')
uselog_months = pd.read_csv('use_log_months.csv')
```

미래를 예측하기 위해 그 달과 1개월 전의 이용 이력만으로 데이터 작성!

why?) 과거 6개월 분의 데이터로부터 이용 횟수 예측하면 가입 5개월 이내의 회원 탈퇴 예측 불가

```python
# 고객별로 연속된 달의 사용량을 비교하는 데이터프레임 생성

year_months = list(uselog_months["연월"].unique())
uselog = pd.DataFrame()

for i in range(1, len(year_months)):
    tmp = uselog_months.loc[uselog_months["연월"]==year_months[i]]
    tmp.rename(columns={"count":"count_0"}, inplace=True)
    tmp_before = uselog_months.loc[uselog_months["연월"]==year_months[i-1]]
    del tmp_before["연월"]
    tmp_before.rename(columns={"count":"count_1"}, inplace=True)
    tmp = pd.merge(tmp, tmp_before, on="customer_id", how="left")
    uselog = pd.concat([uselog, tmp], ignore_index=True)

uselog.head()
```

**`tmp = uselog_months.loc[uselog_months["연월"]==year_months[i]]`**

→ 현재 처리 중인 월에 해당하는 데이터를 uselog_months에서 추출해서 tmp에 저장

count_0 : 현재 월의 사용량

**`tmp_before = uselog_months.loc[uselog_months["연월"] == year_months[i-1]]`**

→ 이전 달에 해당하는 데이터를 추출하여 tmp_before에 저장

count_1 : 이전 월의 사용량

현재 월의 데이터와 이전 월의 데이터 병합한 후 누적!

![2.png](/assets/img/posts/DBS/DBS%205/2.png)

### 2. 탈퇴 전월의 탈퇴 고객 데이터를 작성하자

탈퇴 예측을 어떻게 하지..?

→ 이 스포츠 센터는 월말까지 탈퇴 신청을 해야 다음 달 말에 탈퇴할 수 있음, 따라서 탈퇴 월의 1개월 전에 탈퇴 신청을 할 확률을 예측해야 함!!

```python
# 회원이 탈퇴한 월을 기준으로 이전 월의 사용 데이터 추적

from dateutil.relativedelta import relativedelta

exit_customer = customer.loc[customer["is_deleted"]==1]
exit_customer["exit_date"] = None
exit_customer["end_date"] = pd.to_datetime(exit_customer["end_date"])

for i in range(len(exit_customer)):
    exit_customer["exit_date"].iloc[i] = exit_customer["end_date"].iloc[i] - relativedelta(months=1)
exit_customer["연월"] = pd.to_datetime(exit_customer["exit_date"]).dt.strftime("%Y%m")

uselog["연월"] = uselog["연월"].astype(str)
exit_uselog = pd.merge(uselog, exit_customer, on=["customer_id", "연월"], how="left")

print(len(uselog))
exit_uselog.head()
```

**`exit_customer = customer.loc[customer["is_deleted"]==1]`**

→ 탈퇴한 회원(is_deleted 값이 1인) 행 필터링해서 exit_customer에 저장

**`exit_customer["exit_date"].iloc[i] = exit_customer["end_date"].iloc[i] - relativedelta(months=1)`**

→ i 번째 행의 exit_date열 선택, end_date으로부터 한 달을 빼서 계산된 날짜를 반환해서 exit_date 열의 i 번째 행에 할당하여 업데이트!

→ relativedelta(months=1) : 한 달 전의 날짜를 나타내는 상대적 차이 의미!!

이후 datetime 형식으로 변환 후, “연월”에 저장함

**`uselog["연월"] = uselog["연월"].astype(str)`**

→ 이후 exit_customer와 병합할 때 두 데이터프레임 간의 데이터 형식을 맞추기 위함

exit_uselog 데이터프레임에는 사용기록(uselog)에 탈퇴 회원의 정보를 추가하여, 각 회원의 탈퇴 시점과 그 이전 한 달의 사용 기록을 함께 포함!!

![3.png](/assets/img/posts/DBS/DBS%205/3.png)

데이터 개수 보니까 33851개…

결합한 데이터는 탈퇴한 회원의 탈퇴 전월의 데이터뿐이니까 결측치가 많겠지..?

```python
# 결측치가 있는 행 제거

exit_uselog = exit_uselog.dropna(subset=["name"])

print(len(exit_uselog))
print(len(exit_uselog["customer_id"].unique()))
exit_uselog.head()
```

**`exit_uselog = exit_uselog.dropna(subset=["name"])`**

→ subset=[”name”] 은 “name” 열 만을 대상으로 결측치를 확인해서 제거함

WHY?) 탈퇴한 회원들만 필터링 했으므로 탈퇴하지 않은 회원의 값은 결측치로 되어있겠지!!

![4.png](/assets/img/posts/DBS/DBS%205/4.png)

지금까지 작성한 데이터는 어떤 특정 회원이 그만두기 전월의 상태를 나타내는 데이터

### 지속 회원의 데이터를 작성하자

지속회원을 추출한 후 uselog 데이터에 결합하자!!

```python
# 지속회원 추출해서 uselog 데이터프레임과 병합

conti_customer = customer.loc[customer["is_deleted"]==0]
conti_uselog = pd.merge(uselog, conti_customer, on=["customer_id"], how="left")

print(len(conti_uselog))
conti_uselog = conti_uselog.dropna(subset=["name"])
print(len(conti_uselog))

>>>
33851
27422
```

**`conti_customer = customer.loc[customer["is_deleted"]==0]`**

→ 지속 회원(is_deleted 값이 0인) 행 필터링해서 conti_customer에 저장

근데 위에서 탈퇴회원 데이터는 1104갠데 지속회원 데이터는 27422개네..?

**불균형한 데이터**가 되어버림!!

지속회원 데이터도 회원당 1개가 되게 언더샘플링 하자!!

- **언더샘플링** : 데이터 불균형을 완화하여 모델이 다수 클래스에 편향되지 않도록 함
    - 랜덤 언더샘플링 : 다수 클래스의 데이터를 랜덤하게 선택
    - 클러스터링 기반 언더샘플링 : 다수 클래스의 데이터를 클러스터링한 후, 각 클러스터에서 대표적인 샘플을 선택

```python
# 데이터를 섞고 중복을 제거

conti_uselog = conti_uselog.sample(frac=1).reset_index(drop=True)
conti_uselog = conti_uselog.drop_duplicates(subset="customer_id")

print(len(conti_uselog))
conti_uselog.head()
```

이거는 그냥 중복제거 느낌이긴 함..

**`conti_uselog = conti_uselog.sample(frac=1).reset_index(drop=True)`**

→ sample() 함수는 데이터를 무작위로 섞을 때 사용!!

→ frac=1 은 전체 데이터의 100%를 섞는다는 의미(모든 행)

**`conti_uselog = conti_uselog.drop_duplicates(subset="customer_id")`**

→drop_duplicates(subset=” “) 함수는 “ “ 열을 기준으로 중복된 행 제거

![5.png](/assets/img/posts/DBS/DBS%205/5.png)

이제 데이터 개수가 2842개로 줄었네!!

```python
# 지속회원 데이터와 탈퇴회원 데이터 세로 병합

predict_data = pd.concat([conti_uselog, exit_uselog],ignore_index=True)

print(len(predict_data))
predict_data.head()
```

![6.png](/assets/img/posts/DBS/DBS%205/6.png)

지속회원 + 탈퇴회원 데이터를 predict_date 데이터프레임으로 병합

### 4. 예측할 달의 재적 기간을 작성하자

시간적 요소가 들어간 데이터니까 재적 기간과 같은 데이터를 변수로 이용하자!!

```python
# 재적 기간을 계산해서 period 열에 추가

predict_data["period"] = 0
predict_data["now_date"] = pd.to_datetime(predict_data["연월"], format="%Y%m")
predict_data["start_date"] = pd.to_datetime(predict_data["start_date"])

for i in range(len(predict_data)):
    delta = relativedelta(predict_data["now_date"][i], predict_data["start_date"][i])
    predict_data["period"][i] = int(delta.years*12 + delta.months)

predict_data.head()
```

“연월” 열을 datetime 형식으로 변환해서 now_date 열에 저장

start_date를 datetme 형식으로 변환

**`relativedelta(predict_data["now_date"][i], predict_data["start_date"][i])`**

→ 반복문 돌려서 now_date 와 start_date 간의 차이 계산

**`int(delta.years * 12 + delta.months)`**

→ 총 기간을 월 단위로 계산하고, 정수로 변환

![7.png](/assets/img/posts/DBS/DBS%205/7.png)

### 5. 결측치를 제거하자

이제 슬슬 머신러닝 할 건데 결측치 제거해야겠지??

```python
# 결측치 수 파악

predict_data.isna().sum()

>>>
연월                      0
customer_id             0
count_0                 0
count_1               233
name                    0
class                   0
gender                  0
start_date              0
end_date             2842
campaign_id             0
is_deleted              0
class_name              0
price                   0
campaign_name           0
mean                    0
median                  0
max                     0
min                     0
routine_flg             0
calc_date               0
membership_period       0
exit_date            2842
period                  0
now_date                0
dtype: int64
```

end_date, exit_date, count_1에 결측치가 있는 모습!!

생각해보면 end_date 와 exit_date는 탈퇴회원만 있고, 지속회원은 자동으로 결측치!

→ count_1에 해당하는 결측치만 제거하자 (count_1 : 이전 월의 이용 횟수)

```python
# count_1에 해당하는 결측치 제거

predict_data = predict_data.dropna(subset=["count_1"])
predict_data.isna().sum()

>>>
연월                      0
customer_id             0
count_0                 0
count_1                 0
name                    0
class                   0
gender                  0
start_date              0
end_date             2661
campaign_id             0
is_deleted              0
class_name              0
price                   0
campaign_name           0
mean                    0
median                  0
max                     0
min                     0
routine_flg             0
calc_date               0
membership_period       0
exit_date            2661
period                  0
now_date                0
dtype: int64
```

결측치 처리 완료!!

### 6. 문자열 변수를 처리할 수 있게 가공하자

머신러닝 돌릴 때 문자열 데이터는 어떻게 처리하지..?

이런 데이터를 **카테고리 변수**라고 함!!

→ 앞에서 routine_flg를 작성한 것 처럼 플래그를 만들자! (더미 변수)

```python
# 변수 설정, 예측에 필요한 데이터프레임 추출

target_col = ["campaign_name", "class_name", "gender", "count_1", "routine_flg", "period", "is_deleted"]
predict_data = predict_data[target_col]

predict_data.head()
```

설명 변수로는 "campaign_name", "class_name", "gender", "count_1", "routine_flg", "period"

목적 변수로는 "is_deleted"

![8.png](/assets/img/posts/DBS/DBS%205/8.png)

```python
# 더미 변수 생성

predict_data = pd.get_dummies(predict_data)
predict_data.head()
```

**`get_dumies()`** 함수 이용해서 일괄적으로 더미 변수 생성!!

**더미 변수** : 범주형 변수를 수치형 변수로 변환하기 위한 이진 변수!!

해당 범주의 값이 나타나면 1, 그렇지 않으면 0

주의) 범주가 2개인 경우(남성/여성 & 종일/주간) 하나가 결정되면 하나가 따라 결정되기 때문에 하나씩 지워도 본 기능 수행 가능!!

![9.png](/assets/img/posts/DBS/DBS%205/9.png)

```python
# 하나씩 제거

del predict_data["campaign_name_일반"]
del predict_data["class_name_야간"]
del predict_data["gender_M"]
predict_data.head()
```

![10.png](/assets/img/posts/DBS/DBS%205/10.png)

### 7. 의사결정 트리를 사용해서 탈퇴 예측 모델을 구축하자

이제 의사결정 트리 사용해서 예측 모델 만들어보자!!

```python
# 의사결정 트리 모델 학습

from sklearn.tree import DecisionTreeClassifier
import sklearn.model_selection

exit = predict_data.loc[predict_data["is_deleted"]==1]
conti = predict_data.loc[predict_data["is_deleted"]==0].sample(len(exit))

X = pd.concat([exit, conti], ignore_index=True)
y = X["is_deleted"]
del X["is_deleted"]
X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X,y)

model = DecisionTreeClassifier(random_state=0)
model.fit(X_train, y_train)

y_test_pred = model.predict(X_test)
print(y_test_pred)
```

**`exit = predict_data.loc[predict_data["is_deleted"]==1]`**

**`conti = predict_data.loc[predict_data["is_deleted"]==0].sample(len(exit))`**

→ 아까 지속회원 수가 근소하게 많았으므로 동일한 수의 행 샘플링

**`X = pd.concat([exit, conti], ignore_index=True)`**

→ 탈퇴회원과 지속회원을 하나의 데이터프레임 X로 병합

**`y = X["is_deleted"]`**

**`del X["is_deleted"]`**

→ is_delted 열을 레이블 y로 설정(예측 대상!!!)후 학습 데이터에서 분리!!!

**`X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X,y)`**

→ train_test_split() 을 사용하여 훈련 세트와 테스트 세트로 분리

**`model = DecisionTreeClassifier(random_state=0)`**

**`model.fit(X_train, y_train)`**

→ 의사결정 트리 모델 학습

출력 결과를 보면 0또는 1의 값(0 : 지속 / 1 : 탈퇴)

```python
# 실제 값과 함께 데이터프레임으로 저장

results_test = pd.DataFrame({"y_test":y_test ,"y_pred":y_test_pred })

results_test.head()
```

![11.png](/assets/img/posts/DBS/DBS%205/11.png)

이제 모델을 평가해보자..!!

### 8. 예측 모델을 평가하고, 모델을 튜닝해보자

```python
# 정답률 계산

correct = len(results_test.loc[results_test["y_test"]==results_test["y_pred"]])
data_count = len(results_test)
score_test = correct / data_count
print(score_test)

>>>
0.8821292775665399
```

88% 정도의 정답률이네!!

이렇게 해도 되지만 정확도를 계산해주는 기능이 있음!!

```python
# 모델의 정확도 계산

print(model.score(X_test, y_test))
print(model.score(X_train, y_train))

>>>
0.8821292775665399
0.9784537389100126
```

테스트 세트를 사용한 예측 성능은 88% 이고 훈련 세트를 사용한 예측 성능은 97%네..!!

학습 세트에 너무 과적합 되어있음!!!

→ 데이터 늘리기, 변수 재검토, 모델의 파라미터 변경과 같은 작업

```python
# 깊이를 얕게 해서 모델 단순화

X = pd.concat([exit, conti], ignore_index=True)
y = X["is_deleted"]
del X["is_deleted"]
X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X,y)

model = DecisionTreeClassifier(random_state=0, max_depth=5)
model.fit(X_train, y_train)

print(model.score(X_test, y_test))
print(model.score(X_train, y_train))

>>>
0.9144486692015209
0.9233206590621039
```

max_depth=5로 최대 깊이를 5개로 한정하여 모델 단순화!!

테스트 세트, 훈련 세트간의 격차가 확연히 줄어든 모습

### 9. 모델에 기여하고 있는 변수를 확인하자

```python
# 변수의 기여율 출력

importance = pd.DataFrame({"feature_names":X.columns, "coefficient":model.feature_importances_})
importance

##############4장에서 사용한 기여율 획인 코드###############
coef = pd.DataFrame({"feature_names":X.columns, "coefficient":model.coef_})
coef
###########################################################
```

**`model.feature_importances_`**

→ 의사결정 트리에서 각 특징이 최종 결정에 얼마나 기여하는지를 나타내는 값

**`model.coef_`**

→ 선형모델에서 학습된 가중치(계수)를 나타내는 값

![12.png](/assets/img/posts/DBS/DBS%205/12.png)

재적기간이 탈퇴에 제일 많은 영향!!

정기 이용 여부가 그 다음이네??

해석) 오래 다니면 갈아타는건가…? 아니면 애초에 적게 다녀서 돈 아까워서 탈퇴하나..?

### 10. 회원 탈퇴를 예측하자

설명변수를 참고로 예측을 위한 데이터 만들어서 예측해보자!!

```python
# 예측 데이터 생성

count_1 = 3
routing_flg = 1
period = 10
campaign_name = "입회비무료"
class_name = "종일"
gender = "M"
```

```python
# 회원 탈퇴 여부 예측

if campaign_name == "입회비반값할인":
    campaign_name_list = [1, 0]
elif campaign_name == "입회비무료":
    campaign_name_list = [0, 1]
elif campaign_name == "일반":
    campaign_name_list = [0, 0]
if class_name == "종일":
    class_name_list = [1, 0]
elif class_name == "주간":
    class_name_list = [0, 1]
elif class_name == "야간":
    class_name_list = [0, 0]
if gender == "F":
    gender_list = [1]
elif gender == "M":
    gender_list = [0]

input_data = [count_1, routing_flg, period]
input_data.extend(campaign_name_list)
input_data.extend(class_name_list)
input_data.extend(gender_list)

print(model.predict([input_data]))
print(model.predict_proba([input_data]))

>>>
[1.]
[[0.06185567 0.93814433]]
```

카테고리 변수를 if 문으로 나누면서 더미 변수로 작성

이후 이 데이터를 input_date 라는 리스트에 저장

이후 모델에 넣어 예측!!

→ 탈퇴(1)한다네?

**`model.predict_proba([input_data])`**

→ 각 클래스에 속할 확률 예측!!

93.8%의 확률로 탈퇴하는구나!!!