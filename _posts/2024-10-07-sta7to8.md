---
layout : post
title : "데이터 분석 : 통계 101 데이터 분석 8장 ~ 9장"
date : 2024-10-07
categories : [Data Analysis, Statistics]
---
# 8장 ~ 9장

### 8.1 선형회귀 원리의 확장

- **다중회귀**

설명변수가 여러 개인 것!

![1.png](/assets/img/posts/STATISTIC/STATISTIC8to9/1.png)

![2.png](/assets/img/posts/STATISTIC/STATISTIC8to9/2.png)

기울기 - 편회귀계수

최소제곱법을 이용하여 파라미터 구하기!

![3.png](/assets/img/posts/STATISTIC/STATISTIC8to9/3.png)

편회귀계수와 그 유의성이 중요!!

편회귀계수를 비교하려면 **표준화편회귀계수** 이용!!

![4.png](/assets/img/posts/STATISTIC/STATISTIC8to9/4.png)

상관계수가 1에 가까울 때는 다중공선성이 있는지를 의심해야

- **범주형 변수**

양적 변수가 아닌 범주형 변수는 더미변수 이용!!(0또는 1)

![5.png](/assets/img/posts/STATISTIC/STATISTIC8to9/5.png)

- **공분산분석**

분산분석의 해석 정밀도를 향상사킴!

일반적인 분산분석에 사용하는 데이터 + 양적변수 데이터(공변량)

![6.png](/assets/img/posts/STATISTIC/STATISTIC8to9/6.png)

공분산분석 사용 조건

1. 집단 간 회귀의 기울기가 서로 다르지 않아야
2. 회귀계수가 0이 아니어야
- **다중공선성**

설명변수가 여러 개인 다중회귀에서 설명변수 사이에 강한 상관이 있는 경우 → 다중공선성이 있다!!

![7.png](/assets/img/posts/STATISTIC/STATISTIC8to9/7.png)

![8.png](/assets/img/posts/STATISTIC/STATISTIC8to9/8.png)

다중공선성 정도를 측정하려면?)

**분산팽창인수(VIF)** 계산

![9.png](/assets/img/posts/STATISTIC/STATISTIC8to9/9.png)

각 설명변수마다 VIF 값 산출

하나의 설명변수 x_i를 반응변수로 설정하고, 나머지 설명변수를 이용하여 회귀를 시행한 뒤, 그 결정계수 R² 계산

→ VIF > 10 이라면, 2개 사이의 상관이 아주 강한 것!!!

다중공선성이 강하다고 판단했을 때는, 서로 상관이 있는 2개 변수 중 하나를 없애거나 주성분분석등의 차원 축소 방법을 통해 설명변수의 개수를 줄여야!!

### 8.2 회귀모형의 형태 바꾸기

- **상호작용**

설명변수간의 상승효과!!

- **이원배치 분산분석**

분산분석에 여러 개의 요인을 동시에 고려!

![10.png](/assets/img/posts/STATISTIC/STATISTIC8to9/10.png)

![11.png](/assets/img/posts/STATISTIC/STATISTIC8to9/11.png)

가설검정 결과 상호작용항(c) 이 유의미하지 않다면 상호작용이 없다고 봄

→ 각각의 주효과를 그대로 평가

가설검정 결과 상호작용항(c)이 유의미하다면 상호작용이 있다고 봄

→ 각각의 요인을 나누고 주효과를 하위 검정으로 평가 가능

### 8.3 일반화선형모형의 개념

- **일반화선형모형**

일반선형모형의 원리를 확장하여 최소제곱법이 아닌 확률분포에 기반한 최대가능도 방법(최대우도법)으로 회귀모형을 추정

![12.png](/assets/img/posts/STATISTIC/STATISTIC8to9/12.png)

데이터 성질을 고려하면서 확률 모형을 가정하고. 파라미터를 추정하여 모형을 평가하는 작업을 통계 모형화라 부름!

![13.png](/assets/img/posts/STATISTIC/STATISTIC8to9/13.png)

- **가능도와 최대가능도 방법**

일반선형회귀가 적절하지 않은 데이터에서는

‘확률적으로 얼마나 나타나기 쉬운가’에 기반해 데이터에 잘 들어맞는지 평가

![14.png](/assets/img/posts/STATISTIC/STATISTIC8to9/14.png)

여기서 p(x | θ) 를 ‘가능도’ 라고 함!!

가능도가 크다는 것은, 그 θ에서 얻은 데이터가 나타나기 쉽다

이렇게 가능도를 최대화하는 θ를 찾아서 이를 추정값으로 삼으면 얻은 데이터에 가장 잘 들어맞는 파라미터 추정

→ 최대가능도방법(최대가능도추정) 

![15.png](/assets/img/posts/STATISTIC/STATISTIC8to9/15.png)

- **로지스틱 회귀**

반응변수가 값이 2개인 범주형 변수일 때 사용!!

범주 하나가 일어날 확률을 p로 두고, 설명변수 x가 바뀌었을 때 p가 얼마나 달라는지를 조사

![16.png](/assets/img/posts/STATISTIC/STATISTIC8to9/16.png)

![17.png](/assets/img/posts/STATISTIC/STATISTIC8to9/17.png)

- **로지스틱 함수**

![18.png](/assets/img/posts/STATISTIC/STATISTIC8to9/18.png)

- **오즈비**

로지스틱 회귀의 결과를 오즈비(OR)라는 값으로 평가

‘오즈’ : 어떤 사건이 일어날 확률 p와 일어나지 않을 확률 1-p의 비율

![19.png](/assets/img/posts/STATISTIC/STATISTIC8to9/19.png)

2개의 확률 p와 q에 대한 2개의 오즈 비율을 오즈비(승산비, OR) 이라고 함!!

![20.png](/assets/img/posts/STATISTIC/STATISTIC8to9/20.png)

1보다 크다면, 확률 p가 확률q보다 일어나기 쉽다!

1보다 작다면, 확률q가 확률p보다 일어나기 쉽다!

![21.png](/assets/img/posts/STATISTIC/STATISTIC8to9/21.png)

- **포아송 회귀**

데이터가 음수가 되지 않는 정수, 특히 반응변수가 개수 일 때 고려해볼수 있는 일반화선형모형!!

![22.png](/assets/img/posts/STATISTIC/STATISTIC8to9/22.png)

낮은 확률로 일어나는 무작위 사건에 대해, 평균이 λ번일 때 몇 번 일어나는지를 나타냄!

![23.png](/assets/img/posts/STATISTIC/STATISTIC8to9/23.png)

![24.png](/assets/img/posts/STATISTIC/STATISTIC8to9/24.png)

![25.png](/assets/img/posts/STATISTIC/STATISTIC8to9/25.png)

현실 데이터에는 분포에서 규정된 평균과 분산의 관계보다도 분산이 큰 경우가 있음 → 과분산

포아송 회귀에서 과분산 → 일반화선형혼합모형 사용 (일반화선형모형에 임의효과 적용)

임의 효과 : 입실론(ε) 이라고 생각!!

### 8.4 통계 모형의 평가와 비교

- **왈드 검정**

최대가능도 방법으로 얻은 추정값/표준오차 → 왈드 통계량

최대가능도 추정량이 정규분포를 따른다고 가정,

왈드 통계량을 이용하여 신뢰구간이나 p값

- **가능도비 검정**

전제조건) 비교할 2개의 모형 중 어느 한쪽이 다른 한쪽을 포함하는 관계

귀무가설 : y = a

대립가설 : y = a +bx

각 모형에서 최대가능도 L1*, L2*

![26.png](/assets/img/posts/STATISTIC/STATISTIC8to9/26.png)

![27.png](/assets/img/posts/STATISTIC/STATISTIC8to9/27.png)

부트스트랩 방법 : 무작위로 데이터를 생성하고 추정량의 성질 조사

- **AIC**

새롭게 얻을 데이터를 얼마나 잘 예측할 수 있을지를 바탕으로 적합도 결정

모형의 최대가능도 : L*

모형의 파라미터 개수 : k

![28.png](/assets/img/posts/STATISTIC/STATISTIC8to9/28.png)

여러가지 모형의 AIC 구해서 최소화된 모형을 선택!!

- **BIC**

최대가능도: L*

파라미터 개수: k

표본 크기 : n

![29.png](/assets/img/posts/STATISTIC/STATISTIC8to9/29.png)

표본크기 n이 클수록 파라미터 개수 k의 페널티가 커짐!!

### 9.2 가설검정의 문제점

- **효과크기**

이표본 평균값 비교에서 p<0.05를 얻어 통계적으로 유의하다고 알아도, 평균값에 얼마나 차이가 있는지는 모름

얼마만큼의 효과가 있는지를 나타내는 효과크기 이용!!

→ 평균값의 차이를 나타냄

2개 모집단 평균이 얼마나 떨어져 있는지를 나타내는 Cohen’s d

![30.png](/assets/img/posts/STATISTIC/STATISTIC8to9/30.png)

데이터 값 그 자체(또는 단위)에 의존하지 않도록, 모집단의 분산으로 표준화!!

![31.png](/assets/img/posts/STATISTIC/STATISTIC8to9/31.png)

- **베이즈 인수**

p 값 대신 사용하는 베이즈 인수!!

어떤 모형 M이 얻은 데이터 x를 설명하는 데 얼마나 적절한지?) 주변 가능도/ 에비던스

![32.png](/assets/img/posts/STATISTIC/STATISTIC8to9/32.png)

베이즈 인수 B는 얻은 데이터 x에 대해 2개의 모형을 상정하고, 이 둘의 주변 가능도 비율로써 정의

![33.png](/assets/img/posts/STATISTIC/STATISTIC8to9/33.png)

해석하는데는 여러가지 기준이 있음!

### 9.3 p-해킹

p-해킹 : 의도하든, 의도하지 않든 p값을 원하는 방향으로 조작하는 행위!

![34.png](/assets/img/posts/STATISTIC/STATISTIC8to9/34.png)

![35.png](/assets/img/posts/STATISTIC/STATISTIC8to9/35.png)

![36.png](/assets/img/posts/STATISTIC/STATISTIC8to9/36.png)